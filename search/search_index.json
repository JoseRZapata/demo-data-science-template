{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Demo data science template","text":"<p>This demo of a data science project is created using the template from @JoseRZapata's data science project template which have all the necessary tools for experiment, development, testing, and deployment data science From notebooks to production.</p> <p>[!WARNING] \ud83d\udea7 Work in progress \ud83d\udea7, This is a demo project, It is only for educational purposes.</p>"},{"location":"#project-structure","title":"\ud83d\uddc3\ufe0f Project structure","text":"<pre><code>.\n\u251c\u2500\u2500 codecov.yml                         # configuration for codecov\n\u251c\u2500\u2500 .code_quality\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 bandit.yaml                     # bandit configuration\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 mypy.ini                        # mypy configuration\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 ruff.toml                       # ruff configuration\n\u251c\u2500\u2500 data\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 01_raw                          # raw immutable data\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 02_intermediate                 # typed data\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 03_primary                      # domain model data\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 04_feature                      # model features\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 05_model_input                  # often called 'master tables'\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 06_models                       # serialized models\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 07_model_output                 # data generated by model runs\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 08_reporting                    # reports, results, etc\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 README.md                       # description of the data structure\n\u251c\u2500\u2500 docs                                # documentation for your project\n\u251c\u2500\u2500 .editorconfig                       # editor configuration\n\u251c\u2500\u2500 .github                             # github configuration\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 actions\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 python-poetry-env\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 action.yml              # github action to setup python environment\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 dependabot.md                   # github action to update dependencies\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 pull_request_template.md        # template for pull requests\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 workflows\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 docs.yml                    # github action to build documentation (mkdocs)\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 pre-commit_autoupdate.yml   # github action update pre-commit hooks\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 test.yml                    # github action to run tests\n\u251c\u2500\u2500 .gitignore                          # files to ignore in git\n\u251c\u2500\u2500 Makefile                            # useful commands to setup environment,\n\u251c\u2500\u2500 models                              # store final models\n\u251c\u2500\u2500 notebooks\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 1-data                          # notebooks for data extraction and cleaning\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 2-exploration                   # notebooks for data exploration\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 3-analysis                      # notebooks for data analysis\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 4-feat_eng                      # notebooks for feature engineering\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 5-models                        # notebooks for model training\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 6-evaluation                    # notebooks for model evaluation\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 7-deploy                        # notebooks for model deployment\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 notebook_template.ipynb         # template for notebooks\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 README.md                       # information about the notebooks\n\u251c\u2500\u2500 .pre-commit-config.yaml             # configuration for pre-commit hooks\n\u251c\u2500\u2500 pyproject.toml                      # dependencies for poetry\n\u251c\u2500\u2500 README.md                           # description of your project\n\u251c\u2500\u2500 src                                 # source code for use in this project\n\u251c\u2500\u2500 tests                               # test code for your project\n\u2514\u2500\u2500 .vscode                             # vscode configuration\n    \u251c\u2500\u2500 extensions.json                 # list of recommended extensions\n    \u2514\u2500\u2500 settings.json                   # vscode settings\n</code></pre>"},{"location":"#data-science-code-structure","title":"Data Science Code structure","text":""},{"location":"#orchestrated-experiment","title":"Orchestrated experiment","text":"<pre><code>flowchart TD\n  subgraph input [ETL]\n    %%nodes\n    A1[(Data web)]\n    B[Process_etl]\n    BB1{{Data integrity}}\n    BB2{{Data Validation}}\n    Dcheck[(Data Checked)]\n\n    %%links\n    A1 ==&gt;B\n    B ==&gt; BB1 ==&gt; BB2 ==&gt; Dcheck[(Data Checked)]\n  end\n\n  subgraph split [Train / Test data split]\n    %%nodes\n    C[Split - Train /Test]\n    C1[(Train)]\n    C2[(Test)]\n    CC{{Train / Test Validation}}\n\n    %%links\n    Dcheck ==&gt; C\n    C --&gt; |data test|C2\n    C --&gt; |data train|C1\n    C2 &amp; C1 --&gt; CC\n  end\n\n  subgraph train_feature [Train Feature Engineering]\n    %%nodes\n    D[&lt;b&gt;Pre - process Train&lt;/b&gt; &lt;br&gt; Not needed in test &lt;br&gt; Ex:  Remove outliers, Duplicated, Drops]\n\n\n    subgraph feature [Feature Engineering pipeline &lt;br&gt; for use in train and test]\n      style feature fill:grey,stroke:#333,stroke-width:2px\n      %%nodes\n      E[&lt;b&gt;Initial Processing&lt;/b&gt; &lt;br&gt; Ex: Casting, New columns, Replace empty values for NaN]\n      F{Split &lt;br&gt; Data Type}\n      G1[Transformation &lt;br&gt; Numerics &lt;br&gt; &lt;s&gt;No Drops&lt;/s&gt;]\n      G2[Transformation &lt;br&gt; Categoric &lt;br&gt; &lt;s&gt;No Drops&lt;/s&gt;]\n      G3[Transformation &lt;br&gt; Booleans &lt;br&gt; &lt;s&gt;No Drops&lt;/s&gt;]\n      G4[Transformation &lt;br&gt; Dates &lt;br&gt; &lt;s&gt;No Drops&lt;/s&gt;]\n      G5[Transformation &lt;br&gt; Strings &lt;br&gt; &lt;s&gt;No Drops&lt;/s&gt;]\n      H[&lt;b&gt;Final Processing&lt;/b&gt; &lt;br&gt; Final Pipeline &lt;br&gt; ColumnTranformer &lt;br&gt; and last transforms]\n      TRfit[Train Transformer]\n      TRdb[(Transformer &lt;br&gt; Pipeline)]\n      %%links\n      E -.-&gt; F\n      F -.-&gt;|Numeric|G1\n      F -.-&gt;|Categoric|G2\n      F -.-&gt;|Bool|G3\n      F -.-&gt;|Dates|G4\n      F -.-&gt;|Strings|G5\n      G1 &amp; G2 &amp; G3 &amp; G4 &amp; G5 -.-&gt; H\n\n      H -.-&gt; |objeto pipeline|TRfit\n      TRfit -.-&gt; |objeto pipeline|TRdb\n    end\n\n    %%nodes\n    I[&lt;b&gt;Post - Processing Train&lt;/b&gt; &lt;br&gt; Ej: Data Balance - smote, Drop duplicates &lt;br&gt; Not needed in test]\n\n    %%links\n    C1 ---&gt;D\n    D --&gt; |X - data train &lt;br&gt; pre-processed|E\n    D --&gt; |X - data train &lt;br&gt; pre-processed|TRfit\n    TRfit --&gt; |X - data train &lt;br&gt; transformed|I\n    D --&gt; |Y - data train &lt;br&gt; pre-processed|I\n\n  end\n\n  subgraph mod[Modeling]\n\n    %%nodes\n    J[Modeling]\n    Modeldb[(Train Model &lt;br&gt; candidate)]\n\n    %%links\n    I ---&gt; |X - data train &lt;br&gt; post-processed|J\n    I --&gt; |Y - data train &lt;br&gt; post-processed|J\n    J -.-&gt; |Model Object| Modeldb\n\n  end\n\n  subgraph pred [Prediction]\n    %%nodes\n    TRtest[Transformation &lt;br&gt; X - Data test]\n    Pred_test[Prediction test]\n    Pred_train[Prediction train]\n    Pred_db[(Predictions)]\n\n    %%links\n    C2 --&gt; |X - data test|TRtest\n    TRdb -.-&gt;TRtest\n    TRtest --&gt; |X - data test &lt;br&gt; transformed|Pred_test\n    C2 --&gt; |Y - data test|Pred_test\n    I --&gt; |X - data train &lt;br&gt; post-processed|Pred_train\n    I --&gt; |Y - data train &lt;br&gt; post-processed|Pred_train\n\n    Modeldb -.-&gt; |model|Pred_train --&gt; Pred_db\n    Modeldb -.-&gt; |model|Pred_test --&gt; Pred_db\n  end\n\n  subgraph eval [Evaluation]\n    %%nodes\n    Modelcheck{{Model validation}}\n    M[Eval]\n    N[(Score)]\n\n    %%links\n\n    I  --&gt; |X data train &lt;br&gt; post-processed|Modelcheck\n    I  --&gt; |Y data train &lt;br&gt; post-processed|Modelcheck\n    TRtest --&gt; |X - data test &lt;br&gt; transformed|Modelcheck\n    C2 --&gt; |Y - data test|Modelcheck\n    Modeldb -....-&gt; |model|Modelcheck\n    Pred_db --&gt; M\n    M -.-&gt;N\n  end\n\n  %%links\n\n\n  Modelcheck -..-&gt;  pass{Pass ?}\n  pass -.-&gt; |no|no((Alert!))\n  pass -.-&gt; |yes|si(Execute modeling &lt;br&gt; with all data):::Passclass\n\n\n  %% Definine link styles\n  linkStyle default stroke:blue\n\n  linkStyle 8,10,12,33,35,42,45,46 stroke:orange\n  linkStyle 29,31,38,44 stroke:deepskyblue\n  linkStyle 36,46 stroke:gold\n\n  %% Styling the title subgraph\n  classDef Title stroke-width:0, color:#f66,  font-weight:bold, font-size: 24px;\n\n  class input,train_feature,feature,pred,mod,eval Title\n\n\n  %% Definine node styles\n  classDef Objclass fill:#329cc1;\n  classDef Checkclass fill:#EC5800;\n  classDef Alertclass fill:#FF0000;\n  classDef Passclass fill:#00CC88;\n\n  %% Assigning styles to nodes\n  class C1,C2,Dcheck,TRdb,Modeldb,Pred_db,N Objclass;\n  class BB1,BB2,CC,Modelcheck Checkclass;\n  class no Alertclass;\n  class si Passclass;\n</code></pre>"},{"location":"#deployment","title":"Deployment","text":"<pre><code>flowchart TD\n  orch_exp[Orchestrated Experiment] -.-&gt; Modelcheck\n  Modelcheck{{Model validation}}:::Checkclass -.-&gt; |si| input\n  Modelcheck -.-&gt; |no|stop((Alert! &lt;br&gt; Stop)):::Alertclass\n  subgraph input [ETL]\n   Dcheck[(Data Checked)]:::Objclass\n  end\n  Dcheck ==&gt;  D[&lt;b&gt;Pre - processing&lt;/b&gt;]\n\n  subgraph train_feature [Train Feature Engineering]\n    %%nodes\n    D[&lt;b&gt;Pre - processing Train&lt;/b&gt; &lt;br&gt; Not needed in test &lt;br&gt; Ej: Drop outliers, Duplicates, Drops]\n\n\n    subgraph feature [Feature Engineering pipeline &lt;br&gt; for use in train and test]\n      style feature fill:grey,stroke:#333,stroke-width:2px\n      %%nodes\n      E[&lt;b&gt;Initial Processing &lt;/b&gt; &lt;br&gt; Ej: Casting, New columns, Replace empty values for NaN]\n      F{Split &lt;br&gt; Data Type}\n      G1[Transformation &lt;br&gt; Numerics &lt;br&gt; &lt;s&gt;No Drops&lt;/s&gt;]\n      G2[Transformation &lt;br&gt; Categoric &lt;br&gt; &lt;s&gt;No Drops&lt;/s&gt;]\n      G3[Transformation &lt;br&gt; Booleans &lt;br&gt; &lt;s&gt;No Drops&lt;/s&gt;]\n      G4[Transformation &lt;br&gt; Dates &lt;br&gt; &lt;s&gt;No Drops&lt;/s&gt;]\n      G5[Transformation &lt;br&gt; Strings &lt;br&gt; &lt;s&gt;No Drops&lt;/s&gt;]\n      H[&lt;b&gt;Processing Final&lt;/b&gt; &lt;br&gt; Final Pipeline &lt;br&gt; ColumnTranformer &lt;br&gt;  and final transforms]\n      TRfit[Train Transformer]\n      %%links\n      E -.-&gt; F\n      F -.-&gt;|Numeric|G1\n      F -.-&gt;|Categoric|G2\n      F -.-&gt;|Bool|G3\n      F -.-&gt;|Dates|G4\n      F -.-&gt;|Strings|G5\n      G1 &amp; G2 &amp; G3 &amp; G4 &amp; G5 -.-&gt; H\n\n      H -.-&gt; |objeto pipeline|TRfit\n    end\n\n    %%nodes\n    I[&lt;b&gt;Post - Processing Train&lt;/b&gt; &lt;br&gt; Ej: Data Balance - smote, dorp duplicates &lt;br&gt; Not needed in test]\n\n    %%links\n\n    D --&gt; |X - data train &lt;br&gt; pre-processed|E\n    D --&gt; |X - data train &lt;br&gt; pre-processed|TRfit\n    TRfit --&gt; |X - data train &lt;br&gt; transformed|I\n    D --&gt; |Y - data train &lt;br&gt; pre-processed|I\n\n  end\n\n  subgraph mod[Modeling]\n    J[Train]\n  end\n\n  subgraph artefacto[Artefacto de salida]\n    TRfit -.-&gt; |pipeline object|TRdb[(Transformer &lt;br&gt; Pipeline)]:::Objclass\n    J -.-&gt; |model object| Modeldb[(Train Model &lt;br&gt; Final)]:::Objclass\n  end\n\n  I --&gt; |data post-processed|mod\n  J -.-&gt;N[(Performance &lt;br&gt; Score)]:::Objclass\n\n  N -.-&gt; Scorecheck{{Performance validation &lt;br&gt; Score actual vs anteriores}}:::Checkclass\n  Scorecheck -.-&gt;  pass{Pass ?}\n  pass -.-&gt; |no|no((Alert!)):::Alertclass\n  pass -.-&gt; |yes|si(Send Artifact to Deploy):::Passclass\n  si -.-&gt; artefacto\n\n  linkStyle 19 stroke:deepskyblue\n\n  classDef Objclass fill:#329cc1;\n  classDef Checkclass fill:#EC5800;\n  classDef Alertclass fill:#FF0000;\n  classDef Passclass fill:#00CC88;\n</code></pre>"},{"location":"#credits","title":"Credits","text":"<p>This project was generated from @JoseRZapata's data science project template template.</p>"}]}