# Demo data science template

[![Poetry](https://img.shields.io/endpoint?url=https://python-poetry.org/badge/v0.json)](https://python-poetry.org/)
[![Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/charliermarsh/ruff/main/assets/badge/v1.json)](https://github.com/charliermarsh/ruff)
[![pre-commit](https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&logoColor=white)](https://github.com/pre-commit/pre-commit)
[![Test](https://github.com/JoseRZapata/demo-data-science-template/actions/workflows/test.yml/badge.svg?branch=main)](https://github.com/JoseRZapata/demo-data-science-template/actions/workflows/test.yml)
[![codecov](https://codecov.io/gh/JoseRZapata/demo-data-science-template/graph/badge.svg?token=PpCcK9jKy9)](https://codecov.io/gh/JoseRZapata/demo-data-science-template)
---

This demo of a data science project is created using the template from [@JoseRZapata]'s [data science project template] which have all the necessary tools for experiment, development, testing, and deployment data science From notebooks to production.

> [!WARNING]
> ðŸš§ Work in progress ðŸš§, This is a demo project, It is only for educational purposes.

## ðŸ—ƒï¸ Project structure

```bash
.
â”œâ”€â”€ codecov.yml                         # configuration for codecov
â”œâ”€â”€ .code_quality
â”‚Â Â  â”œâ”€â”€ bandit.yaml                     # bandit configuration
â”‚Â Â  â”œâ”€â”€ mypy.ini                        # mypy configuration
â”‚Â Â  â””â”€â”€ ruff.toml                       # ruff configuration
â”œâ”€â”€ data
â”‚Â Â  â”œâ”€â”€ 01_raw                          # raw immutable data
â”‚Â Â  â”œâ”€â”€ 02_intermediate                 # typed data
â”‚Â Â  â”œâ”€â”€ 03_primary                      # domain model data
â”‚Â Â  â”œâ”€â”€ 04_feature                      # model features
â”‚Â Â  â”œâ”€â”€ 05_model_input                  # often called 'master tables'
â”‚Â Â  â”œâ”€â”€ 06_models                       # serialized models
â”‚Â Â  â”œâ”€â”€ 07_model_output                 # data generated by model runs
â”‚Â Â  â”œâ”€â”€ 08_reporting                    # reports, results, etc
â”‚Â Â  â””â”€â”€ README.md                       # description of the data structure
â”œâ”€â”€ docs                                # documentation for your project
â”œâ”€â”€ .editorconfig                       # editor configuration
â”œâ”€â”€ .github                             # github configuration
â”‚Â Â  â”œâ”€â”€ actions
â”‚Â Â  â”‚Â Â  â””â”€â”€ python-poetry-env
â”‚Â Â  â”‚Â Â      â””â”€â”€ action.yml              # github action to setup python environment
â”‚Â Â  â”œâ”€â”€ dependabot.md                   # github action to update dependencies
â”‚Â Â  â”œâ”€â”€ pull_request_template.md        # template for pull requests
â”‚Â Â  â””â”€â”€ workflows
â”‚Â Â      â”œâ”€â”€ docs.yml                    # github action to build documentation (mkdocs)
â”‚Â Â      â”œâ”€â”€ pre-commit_autoupdate.yml   # github action update pre-commit hooks
â”‚Â Â      â””â”€â”€ test.yml                    # github action to run tests
â”œâ”€â”€ .gitignore                          # files to ignore in git
â”œâ”€â”€ Makefile                            # useful commands to setup environment,
â”œâ”€â”€ models                              # store final models
â”œâ”€â”€ notebooks
â”‚Â Â  â”œâ”€â”€ 1-data                          # notebooks for data extraction and cleaning
â”‚Â Â  â”œâ”€â”€ 2-exploration                   # notebooks for data exploration
â”‚Â Â  â”œâ”€â”€ 3-analysis                      # notebooks for data analysis
â”‚Â Â  â”œâ”€â”€ 4-feat_eng                      # notebooks for feature engineering
â”‚Â Â  â”œâ”€â”€ 5-models                        # notebooks for model training
â”‚Â Â  â”œâ”€â”€ 6-evaluation                    # notebooks for model evaluation
â”‚Â Â  â”œâ”€â”€ 7-deploy                        # notebooks for model deployment
â”‚Â Â  â”œâ”€â”€ notebook_template.ipynb         # template for notebooks
â”‚Â Â  â””â”€â”€ README.md                       # information about the notebooks
â”œâ”€â”€ .pre-commit-config.yaml             # configuration for pre-commit hooks
â”œâ”€â”€ pyproject.toml                      # dependencies for poetry
â”œâ”€â”€ README.md                           # description of your project
â”œâ”€â”€ src                                 # source code for use in this project
â”œâ”€â”€ tests                               # test code for your project
â””â”€â”€ .vscode                             # vscode configuration
    â”œâ”€â”€ extensions.json                 # list of recommended extensions
    â””â”€â”€ settings.json                   # vscode settings
```

## Data Science Code structure

### Orchestrated experiment

```mermaid
flowchart TD
  subgraph input [ETL]
    %%nodes
    A1[(Data web)]
    B[Process_etl]
    BB1{{Data integrity}}
    BB2{{Data Validation}}
    Dcheck[(Data Checked)]

    %%links
    A1 ==>B
    B ==> BB1 ==> BB2 ==> Dcheck[(Data Checked)]
  end

  subgraph split [Train / Test data split]
    %%nodes
    C[Split - Train /Test]
    C1[(Train)]
    C2[(Test)]
    CC{{Train / Test Validation}}

    %%links
    Dcheck ==> C
    C --> |data test|C2
    C --> |data train|C1
    C2 & C1 --> CC
  end

  subgraph train_feature [Train Feature Engineering]
    %%nodes
    D[<b>Pre - process Train</b> <br> Not needed in test <br> Ex:  Remove outliers, Duplicated, Drops]


    subgraph feature [Feature Engineering pipeline <br> for use in train and test]
      style feature fill:grey,stroke:#333,stroke-width:2px
      %%nodes
      E[<b>Initial Processing</b> <br> Ex: Casting, New columns, Replace empty values for NaN]
      F{Split <br> Data Type}
      G1[Transformation <br> Numerics <br> <s>No Drops</s>]
      G2[Transformation <br> Categoric <br> <s>No Drops</s>]
      G3[Transformation <br> Booleans <br> <s>No Drops</s>]
      G4[Transformation <br> Dates <br> <s>No Drops</s>]
      G5[Transformation <br> Strings <br> <s>No Drops</s>]
      H[<b>Final Processing</b> <br> Final Pipeline <br> ColumnTranformer <br> and last transforms]
      TRfit[Train Transformer]
      TRdb[(Transformer <br> Pipeline)]
      %%links
      E -.-> F
      F -.->|Numeric|G1
      F -.->|Categoric|G2
      F -.->|Bool|G3
      F -.->|Dates|G4
      F -.->|Strings|G5
      G1 & G2 & G3 & G4 & G5 -.-> H

      H -.-> |objeto pipeline|TRfit
      TRfit -.-> |objeto pipeline|TRdb
    end

    %%nodes
    I[<b>Post - Processing Train</b> <br> Ej: Data Balance - smote, Drop duplicates <br> Not needed in test]

    %%links
    C1 --->D
    D --> |X - data train <br> pre-processed|E
    D --> |X - data train <br> pre-processed|TRfit
    TRfit --> |X - data train <br> transformed|I
    D --> |Y - data train <br> pre-processed|I

  end

  subgraph mod[Modeling]

    %%nodes
    J[Modeling]
    Modeldb[(Train Model <br> candidate)]

    %%links
    I ---> |X - data train <br> post-processed|J
    I --> |Y - data train <br> post-processed|J
    J -.-> |Model Object| Modeldb

  end

  subgraph pred [Prediction]
    %%nodes
    TRtest[Transformation <br> X - Data test]
    Pred_test[Prediction test]
    Pred_train[Prediction train]
    Pred_db[(Predictions)]

    %%links
    C2 --> |X - data test|TRtest
    TRdb -.->TRtest
    TRtest --> |X - data test <br> transformed|Pred_test
    C2 --> |Y - data test|Pred_test
    I --> |X - data train <br> post-processed|Pred_train
    I --> |Y - data train <br> post-processed|Pred_train

    Modeldb -.-> |model|Pred_train --> Pred_db
    Modeldb -.-> |model|Pred_test --> Pred_db
  end

  subgraph eval [Evaluation]
    %%nodes
    Modelcheck{{Model validation}}
    M[Eval]
    N[(Score)]

    %%links

    I  --> |X data train <br> post-processed|Modelcheck
    I  --> |Y data train <br> post-processed|Modelcheck
    TRtest --> |X - data test <br> transformed|Modelcheck
    C2 --> |Y - data test|Modelcheck
    Modeldb -....-> |model|Modelcheck
    Pred_db --> M
    M -.->N
  end

  %%links


  Modelcheck -..->  pass{Pass ?}
  pass -.-> |no|no((Alert!))
  pass -.-> |yes|si(Execute modeling <br> with all data):::Passclass


  %% Definine link styles
  linkStyle default stroke:blue

  linkStyle 8,10,12,33,35,42,45,46 stroke:orange
  linkStyle 29,31,38,44 stroke:deepskyblue
  linkStyle 36,46 stroke:gold

  %% Styling the title subgraph
  classDef Title stroke-width:0, color:#f66,  font-weight:bold, font-size: 24px;

  class input,train_feature,feature,pred,mod,eval Title


  %% Definine node styles
  classDef Objclass fill:#329cc1;
  classDef Checkclass fill:#EC5800;
  classDef Alertclass fill:#FF0000;
  classDef Passclass fill:#00CC88;

  %% Assigning styles to nodes
  class C1,C2,Dcheck,TRdb,Modeldb,Pred_db,N Objclass;
  class BB1,BB2,CC,Modelcheck Checkclass;
  class no Alertclass;
  class si Passclass;
```

### Deployment

```mermaid
flowchart TD
  orch_exp[Orchestrated Experiment] -.-> Modelcheck
  Modelcheck{{Model validation}}:::Checkclass -.-> |si| input
  Modelcheck -.-> |no|stop((Alert! <br> Stop)):::Alertclass
  subgraph input [ETL]
   Dcheck[(Data Checked)]:::Objclass
  end
  Dcheck ==>  D[<b>Pre - processing</b>]

  subgraph train_feature [Train Feature Engineering]
    %%nodes
    D[<b>Pre - processing Train</b> <br> Not needed in test <br> Ej: Drop outliers, Duplicates, Drops]


    subgraph feature [Feature Engineering pipeline <br> for use in train and test]
      style feature fill:grey,stroke:#333,stroke-width:2px
      %%nodes
      E[<b>Initial Processing </b> <br> Ej: Casting, New columns, Replace empty values for NaN]
      F{Split <br> Data Type}
      G1[Transformation <br> Numerics <br> <s>No Drops</s>]
      G2[Transformation <br> Categoric <br> <s>No Drops</s>]
      G3[Transformation <br> Booleans <br> <s>No Drops</s>]
      G4[Transformation <br> Dates <br> <s>No Drops</s>]
      G5[Transformation <br> Strings <br> <s>No Drops</s>]
      H[<b>Processing Final</b> <br> Final Pipeline <br> ColumnTranformer <br>  and final transforms]
      TRfit[Train Transformer]
      %%links
      E -.-> F
      F -.->|Numeric|G1
      F -.->|Categoric|G2
      F -.->|Bool|G3
      F -.->|Dates|G4
      F -.->|Strings|G5
      G1 & G2 & G3 & G4 & G5 -.-> H

      H -.-> |objeto pipeline|TRfit
    end

    %%nodes
    I[<b>Post - Processing Train</b> <br> Ej: Data Balance - smote, dorp duplicates <br> Not needed in test]

    %%links

    D --> |X - data train <br> pre-processed|E
    D --> |X - data train <br> pre-processed|TRfit
    TRfit --> |X - data train <br> transformed|I
    D --> |Y - data train <br> pre-processed|I

  end

  subgraph mod[Modeling]
    J[Train]
  end

  subgraph artefacto[Artefacto de salida]
    TRfit -.-> |pipeline object|TRdb[(Transformer <br> Pipeline)]:::Objclass
    J -.-> |model object| Modeldb[(Train Model <br> Final)]:::Objclass
  end

  I --> |data post-processed|mod
  J -.->N[(Performance <br> Score)]:::Objclass

  N -.-> Scorecheck{{Performance validation <br> Score actual vs anteriores}}:::Checkclass
  Scorecheck -.->  pass{Pass ?}
  pass -.-> |no|no((Alert!)):::Alertclass
  pass -.-> |yes|si(Send Artifact to Deploy):::Passclass
  si -.-> artefacto

  linkStyle 19 stroke:deepskyblue

  classDef Objclass fill:#329cc1;
  classDef Checkclass fill:#EC5800;
  classDef Alertclass fill:#FF0000;
  classDef Passclass fill:#00CC88;
```

## Credits

This project was generated from [@JoseRZapata]'s [data science project template] template.

---
[@JoseRZapata]: https://github.com/JoseRZapata

[bandit]: https://github.com/PyCQA/bandit
[codecov]: https://codecov.io/
[Cookiecutter]:https://cookiecutter.readthedocs.io/stable/
[coverage.py]: https://coverage.readthedocs.io/
[Cruft]: https://cruft.github.io/cruft/
[data science project template]: https://github.com/JoseRZapata/data-science-project-template
[Data structure]: demo-data-science-template/data/README.md
[deepcheck]:https://deepcheck.io/
[dependabot]: https://github.com/dependabot/dependabot-core
[depy]:https://fpgmaas.github.io/deptry/
[DVC]:https://dvc.org/
[github actions]: https://github.com/features/actions
[hydra]: https://hydra.cc/
[Jupyter]:https://jupyter.org/
[Makefile]: https://www.gnu.org/software/make/manual/make.html
[MlFlow]:https://www.mlflow.org/
[Mypy]: http://mypy-lang.org/
[Notebook template]: demo-data-science-template/notebooks/notebook_template.ipynb
[NumPy]:https://numpy.org/
[OmegaConf]: https://omegaconf.readthedocs.io/en/latest/
[Pandas]:https://pandas.pydata.org/
[pandera]:(https://pandera.readthedocs.io/en/stable/)
[Poetry]: https://python-poetry.org/
[pre-commit]: https://pre-commit.com/
[Pull Request template]: demo-data-science-template/.github/pull_request_template.md
[Pyenv]: https://github.com/pyenv/pyenv
[pypi]: https://pypi.org/
[Pytest]: https://docs.pytest.org/en/latest/
[pyupgrade]: https://github.com/asottile/pyupgrade
[Ruff]: https://docs.astral.sh/ruff/
[scikit-learn]:https://scikit-learn.org/
